// code by jph
package ch.alpine.surich.ch06.maxbias;

import ch.alpine.subare.alg.ActionValueIteration;
import ch.alpine.subare.alg.Random1StepTabularQPlanning;
import ch.alpine.subare.util.ActionValueStatistics;
import ch.alpine.subare.util.DefaultLearningRate;
import ch.alpine.subare.util.DiscreteQsa;
import ch.alpine.subare.util.DiscreteUtils;
import ch.alpine.subare.util.DiscreteValueFunctions;
import ch.alpine.subare.util.Infoline;
import ch.alpine.subare.util.TabularSteps;
import ch.alpine.tensor.Scalar;
import ch.alpine.tensor.sca.Chop;

enum RSTQP_Maxbias {
  ;
  static void main() {
    Maxbias maxbias = new Maxbias(3);
    DiscreteQsa ref = MaxbiasHelper.getOptimalQsa(maxbias);
    DiscreteQsa qsa = DiscreteQsa.build(maxbias);
    Random1StepTabularQPlanning rstqp = Random1StepTabularQPlanning.of( //
        maxbias, qsa, DefaultLearningRate.of(3, 0.51));
    ActionValueStatistics avs = new ActionValueStatistics(maxbias);
    int batches = 5000;
    for (int index = 0; index < 500; ++index)
      TabularSteps.batch(maxbias, maxbias, rstqp, avs);
    Infoline.print(maxbias, batches, ref, qsa);
    System.out.println("---");
    ActionValueIteration avi = ActionValueIteration.of(maxbias, avs);
    avi.untilBelow(Chop._04);
    DiscreteUtils.print(avi.qsa());
    {
      Scalar error = DiscreteValueFunctions.distance(ref, avi.qsa());
      System.out.println("avs error=" + error);
    }
  }
}
